---
title: "AI Could Destroy Humanity, Experts Say"
description: "If you are a sucker for sci-fi movies, you might remember the basic plot of James Cameron’s&nbsp;Terminator&nbsp;movies if you have watched them. The Terminator’s story revolves around a dystopian future where advanced artificial intelligence systems, known as&nbsp;Skynet, become self-aware and initiate a global war against humanity. Well, guess what? We are going towards that future; [&hellip;]"
pubDate: 2023-06-04
heroImage: "/blog-images/wp-a-cyberpunk-robot-kneeling-down-in-the-middle-of-a-post-apocalyptic-destroyed-city-its-holding-som-787712683.png"
categories: ["Artificial Intelligence","Stories"]
tags: ["AI","Artificial Generative Intelligence","Artificial Intelligence","future","OpenAI","thedeveloperstory"]
---

If you are a sucker for sci-fi movies, you might remember the basic plot of James Cameron’s [Terminator](https://www.imdb.com/title/tt0088247/) movies if you have watched them.

_The Terminator’s story revolves around a dystopian future where advanced artificial intelligence systems, known as_ [_Skynet_](https://en.wikipedia.org/wiki/Skynet_(Terminator))_, become self-aware and initiate a global war against humanity._

Well, guess what? We are going towards that future; I am not even exaggerating.

A group of top artificial intelligence experts and executives warned that the technology poses a “_risk of extinction_” in an alarming joint statement released on May 30, 2023.

More than 350 prominent figures, including the “_Godfather of AI_”, [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), and the most popular AI company’s boss, [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman), see AI as an existential threat, according to the one-sentence open letter organized by the non-profit Centre for AI Safety.

> “_Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war._”
> 
> [Joint statement from the AI experts](https://www.safe.ai/statement-on-ai-risk)

The brief statement is the latest in a series of warnings from prominent researchers about AI’s potential to cause social instability, with potential threats including disinformation propagated, massive economic upheaval due to job losses, and even open attacks on humans.

As a matter of fact, [Hinton recently resigned from his part-time work as an AI researcher at Google](https://edition.cnn.com/2023/05/01/tech/geoffrey-hinton-leaves-google-ai-fears/index.html) in order to talk more freely about his worries. He recently stated that he now partly regrets his life’s work, which may allow “bad actors” to do “bad things” that will be impossible to prevent.

I mean, this is exactly what the “_Father of the atomic bomb_,” [Oppenheimer](https://en.wikipedia.org/wiki/J._Robert_Oppenheimer), felt when he realized what he had created and what it could do to mankind.

You might have read or heard about billionaire [Elon Musk, who was among hundreds of experts who called for a six-month pause in advanced AI development](https://www.cbsnews.com/news/elon-musk-open-letter-ai/) so that leaders could consider how to safely proceed. This is because things are moving extremely fast.

As of this writing, every country with the resources is building their own AI and integrating it into their weapon systems, and that’s fine.

However, what if there have been enough advancements in artificial general intelligence (AGI) that it can do tasks autonomously in the most efficient way possible, and somehow an AI sentient becomes so self-aware that they consider there is no need for humanity?

I recall the interaction between AI sentient Ultron and the superhero group Avengers from the movie [_Avengers: Age of Ultron_](https://www.imdb.com/title/tt2395427/).

For those of you who might not know (_I am sure everyone knows, but still_), Ultron, in the movie is an artificial intelligent program developed for peacekeeping, but it develops consciousness and decides that the only way to achieve peace is to eradicate humanity.

Small snippet of the interaction from the movie | Credit: Marvel

Well, guess what?

Last year, a [Google engineer was suspended because he was claiming that the AI chatbot _(probably Google Bard)_ he was working on had become sentient](https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/) and was thinking and reasoning like a human being. Surely, Google dismissed any such claims.

Sure, here is the corrected and enhanced version of your text:

I’m just saying that the AI race is on, and the market is responding positively to companies that are working on AI or incorporating AI into their businesses.

The sole reason for this is that [AI has the potential to disrupt several industries](https://thedeveloperstory.com/2023/01/27/how-artificial-intelligence-will-change-the-software-development-industry-in-2023/), and investors are eager to get in on the ground floor of this new technology.

However, we should also not forget the potential risks of artificial intelligence. We must demand that leaders around the world enact laws that protect our rights and liberties, and we must hold them accountable when they fail to do so.

* * *

kofiwidget2.init('Support Me on Ko-fi', '#29abe0', 'Z8Z8E5CX3');kofiwidget2.draw();